--A Developer's Guide to Ariadne--

Why read this?

If you are interested in contributing new features to ariadne or just want to 
make the most of your plugins, you should read this document.

Table of Contents:
1 - Introduction to Pipelines
    1.1 - How they are executed
    1.2 - Why this execution model?
2 - Introduction to Plugins and the Plugin API
    2.1 - Plugin class overview
    2.2 - plugin.Plugin
    2.3 - plugin.DatasetPlugin
    2.4 - plugin.ArchivePlugin
    2.5 - plugin.AriadneOp
    2.6 - plugin.AriadneMLOp
    2.7 - Plugin definition notes
3 - Pipeline Definition Files
    3.1 - List of implemented blocks
    3.2 - Example definition file
4 - Dataset Definition Files
    4.1 - Dataset example
5 - The tools module
    5.1 - List of functions
6 - The plugin module
    6.1 - List of functions
    6.2 - List of global data structures
7 - The dataset module
    7.1 - List of functions
8 - The ariadne module
    8.1 - List of functions.
9 - The pipeline module
10 - The plugingen module
11 - Future development directions

1 - Introduction to Pipelines

Pipelines form the most important level of execution to ariadne. They define 
both how a pipeline is to be run (ie. by which methods and through which
plugins) and in what environment it is to be run. Fundamentally, a pipeline is
merely a list of plugins, each with their own dependencies, tests, and
benchmarks.

1.1 - How they are executed

Internally, ariadne starts by building a dictionary of arguments passed on the
command line. It then proceeds to find a pipeline definition file with the
specified name, parse it, and build an object (of type Pipeline). From there,
it calls that object's run() method, which compiles the pipeline to a series
of luigi modules (see plugingen), then finally executes luigi in sequence on 
all of the generated modules. Finally, luigi builds a dependency graph and
executes the generated modules, which are, in turn, wrappers for calls back to
ariadne to execute the plugins in the pipeline in the correct order.

1.2 - Why this execution model?

While this method of executing each pipeline may seem complex, it was 
implemented for several reasons:

* There was development work in implementing a process scheduling/management
    framework for ariadne. Overall, it offered fewer features than luigi and
    ultimately reinvented the wheel.

* Luigi can schedule tasks to run remotely.

* This model will ultimately be more useful for continuous pipeline execution.

2 - Introduction to Plugins and the Plugin API

The fundamental unit of execution of ariadne is the plugin. Each plugin is a 
python module containing a class (with some specific markup) that provides
additional behavior that could not have been foreseen during ariadne's 
development.

2.1 - Plugin class overview

The following base classes are exposed by ariadne at the time of this writing:

* plugin.Plugin - Obsolete base plugin class.

* plugin.DatasetPlugin - Plugin with special methods for dataset retrieval and
    management.

* plugin.ArchivePlugin - Plugin with special methods for archive packing, 
    unpacking, etc.

* plugin.AriadneOp - Base class for generic plugins.

* plugin.AriadneMLOp - Extension of AriadneOp with machine learning-specific
    features.

2.2 - plugin.Plugin

Although this class is mostly unused and will likely be depreciated in future
releases, it is still often useful when doing extremely basic plugin tasks.

List of plugin methods:
* run() - Called to run the plugin

* depends() - Returns a list of DependencyContainers specifying all plugin 
    dependencies.

* benchmark() - Called to perform a benchmark.

* test() -- Called to perform a test.

* print_benchmark() - Called to print benchmark results (NOTE: unused)

* __init__(args, conffile, conftoks) - Constructor for the plugin. Is currently
    called with blank or None values for all constructor parameters.

2.3 - plugin.DatasetPlugin

Because datasets are generally fetched and unpacked in the same way, much of the
boilerplate for automatically downloading and unpacking datasets is already 
implemented by this plugin. All that is necessary to take advantage of this
existing implementation is to override the __init__(def_filename, def_tokens)
method with one that can parse and set the class' data_list attribute. 

List of plugin methods:
* can_handle(dataset_type) - Returns 1 if the plugin can handle the specified
    dataset type string.

* validate() -- Returns 1 if the dataset was correctly fetched and unpacked.

* fetch(destination) - Fetches a dataset and puts it in the destination listed.

* unpack(destination) - Unpacks the dataset and stores its contents in
    destination.

* get_file_list(destination) - Returns a list of all files in the dataset. 
    This method is likely to be depreciated, as its functionality is replicated
    in the dataset module.

* get_file(destination, name, mode) - Returns a file handle to the specified
    file with the specified mode. This allows users to be abstracted from 
    dataset internals and implementation details.

* __init__(def_filename, def_tokens) - Constructor. 

2.4 - plugin.ArchivePlugin

In order to support a wide range of archive types, ariadne allows for archive
utilities to be wrapped in the form of ArchivePlugins.

Note on archive types:
Ariadne specifies archive types by extension. For example, an archive named
"myarchive.tar.gz" would be represented as ".tar.gz". Note that this includes
the leading period on the extension.

List of plugin methods:
* can_handle(extension) - Returns 1 if the plugin can handle archives with the 
    provided extension.

* unpack(file_name, destination) - Unpacks the file referred to by file_name
    in the provided directory.

2.5 - plugin.AriadneOp

This class is effectively a continuation of the original plugin.Plugin class.

List of plugin methods:
* run(arg_dict) - Runs the plugin with the given argument dictionary.

* files_modified() - Returns a list of all files modified by the plugin.

* get_arg_names() - Returns a list of all indices used by run(arg_dict)

* depends() - Returns a list of DependencyContainers needed to run the plugin.

* test() - Executes any nose tests imported or defined by the plugin.

2.6 - plugin.AriadneMLOp

AriadneMLOp is an extension of AriadneOp created to handle machine learning 
specific pipeline tasks.

List of plugin methods added by AriadneMLOp:
* benchmark(arg_dict) - Performs a benchmarking operation (specific benchmarks
    are to be defined per use case) given the provided set of arguments.

* get_train_arg_names() - Returns a list of argument names used by the 
    train(args) method.

* train(args) - performs training operations given an argument dictionary 
    equivalent to that of the run(args) method.

* train_depends() - Returns a list of DependencyContainers specific to the
    train(args) method.

2.7 - Plugin definition notes

In order to do its job, ariadne's plugin loader makes a few assumptions about
each plugin when it is loaded. 

Assumptions made:
1. That each plugin module contains an attribute named "plugin_class" containing
    the name of the class to load. 

2. That each plugin class has an attribute named "name" that contains the name 
    by which that plugin can be identified.

3. That each entry in any given directory's plugin list file is in that 
    directory.

3 - Pipeline definition files

Each pipeline is defined in a number of blocks that can be searched and 
converted into dictionaries using standard deftools functions. 

3.1 - List of implemented blocks

All of the blocks listed below are used by ariadne. All other top level blocks 
are ignored and may contain comments or other information.

* stages - Defines a list of blocks containing all of the stages to execute.

* environment - Defines the environment in which the pipeline is to be run.

* plugindir - Lists all directories containing additional plugins used by
    the pipeline. 

3.2 - Example definition file

    stages:
        stage1:
            plugin: stageplugin
            runtype: run
        end

        stage2:
            plugin: anotherplugin
            runtype: train
        end
    end

    environment:
        FOO=bar
    end

    plugindir:
        plugins
    end

4 - Dataset definition files

Because dataset definition files are so simple from a structural perspective,
this section will contain an example with all attributes in context.

4.1 - Dataset example

    name:
        train-dataset
    type:
        dataset/hdf5
    urls:
        http://my.site/path/to/my/data.h5
        http://my.site/path/to/my/otherdata.h5
    description:
        A training dataset example.

5 - The tools module

Any functions, methods, or classes that are generally useful for a number of
ariadne operations are implemented in the tools module. This section will
provide a general overview of the functions and capabilities provided.

5.1 - List of functions

* get_extension(name) - Returns the extension for a given filename.

* get_url_filename(url) - Attempts to get the file any given URL is pointing to.
    Example: http://my.site/file.txt -> file.txt

* get_url_extension(url) - Attempts to get the file extension for a given URL.
    Example: http://my.site/file.txt -> .txt

* file_exists(filename, [extensions]) - Returns 1 if the specified file or
    the specified file with any of the list of extensions appended exists.
* get_base_dir() - Gets ariadne's install path.

* get_default_dataset_dir() - Returns the default directory in which ariadne
    will search for dataset definition files.

* get_default_config_file() - Returns a path to the default configuration file.

* get_default_conf_toks() - Generates a list of default tokens used to 
    automatically generate a configuration file if there isn't one already.

* prep_default_config_file(conffile) - Creates a default directory structure
    and writes a default configuration to the file name given.

* init_plugins([dir]) - Either initializes all plugins in the default plugins
    directory or the directory specified.

* getenv(var_name) - Attempts to return the environment variable specified.

* setenv(var_name, value) - Attempts to set an environment variable to the
    value specified. Assumes that the value given is a string.

* get_dir_delta(beforelisting, afterlisting) - While this is specifically 
    intended for directory listings, this function computes a list of 
    differences between two lists. The return value is a list of tuples
    in the form (added/removed, value). If a list value was added, the first
    entry in the tuple will be 1. If it is the same, the first entry in the 
    tuple will be 0. If it has been removed, the first entry in the tuple
    will be -1.

    Given ['a', 'b'] and ['b', 'c'], this function should return 
        [(-1, 'a'), (0, 'b'), (1, 'c')]

6 - The plugin module

The plugin module contains methods and functions related to searching for, 
loading, and running plugins. Please note that because (more or less) all of
the classes contained in this module have been described in other documentation,
only functions, definitions, and global data structures will be detailed here.

6.1 - List of functions

* load_plugin(module_name) - Attempts to load a plugin with the given module
    name. This module must exist in python's path (load_plugins() updates the 
    path for you). 

* load_plugins(list_file, base_dir) - Loads all plugins listed in the given
    file from the provided directory.

* get_plugins(plugin_type) - Returns all plugins of the specified type. This
    type is determined at load time by each plugin's list entry.

* search_plugins(plugin_name) - Returns the first plugin class with the 
    specified name.

* get_can_handle(ext) - Returns the first plugin that can handle the specified
    extension or type string.

* set_config(conf_dict) - Updates the global configuration dictionary to the
    specified value.

* get_temp_filename(filename) - Mangles the specified filename and appends 
    a directory so that it may be created and used.

* get_dataset_real_list(dataset_filename) - Returns all scanned URL filenames
    in the given dataset definition file.

6.2 - List of global data structures

* config_dict - Global configuration dictionary. This contains a set of keys
    related to a number aspects of ariadne's operation ranging from default
    behavior to storage directories.

* plugin_list - A list of plugin entries. Each plugin entry is a list in the 
    following form: [plugin class, plugin type string.]

* PLUGIN_TYPE_ARCHIVE - A string denoting the default archive plugin class.
    This and other such attributes will eventually be depreciated and removed.

* PLUGIN_TYPE_GENERIC - A string denoting the default generic plugin class
    Instead of AriadneOp, it is currently set to Plugin.

* PLUGIN_TYPE_DATASET - A string denoting the default dataset plugin class.

* PLUGIN_TYPE_VALIDATION - An unused string containing the name of a class
    that may be implemented to handle common validation tasks.

* PLUGIN_TYPE_EXECUTOR - An unused string containing the name of a class
    that handled pipeline execution. This has been functionally replaced with
    the current luigi execution model.

7 - The dataset module

The dataset module was initially created in order to consolidate dataset 
functionality for plugin developers (given that they are using ariadne to manage
datasets rather than some other library). As such, it contains a number of
functions that should automate the task of searching for appropriate dataset
plugins, fetching datasets, unpacking them, and getting appropriate file 
handles.

7.1 - List of functions

* fetchunpack_dataset(dataset_name, [destination]) - Fetches and unpacks the 
    specified dataset (if if can be found) in either the specified location or a
    default dataset storage directory. Returns either None or the dataset's
    final destination.

* check_dataset_fetched(datasetname, [destination]) - Checks whether the dataset
    specified has been fetched. Returns 1 if it has, 0 if it has not.

* get_dataset_files(dataset_name, dataset_dir) - Returns a list of all of the 
    files fetched and unpacked from a given dataset.

* get_dataset_plugin(datasetname) - Returns an appropriate dataset plugin for the
    given dataset name (if it can be found). Returns None if this is not 
    possible.

8 - The ariadne module

This module contains all of the main execution logic for ariadne's CLI. As such,
its functions are not likely to be useful for most implementation or 
development tasks.

8.1 - List of functions

* print_usage() - Prints a usage statement showing all of ariadne's commands.

* print_dataset_usage() - Prints a usage statement for ariadne's dataset command.

* print_pipeline_usage() - Prints a usage statement for ariadne's pipeline 
    command.

* ..._usage() - Prints a usage statement for ... command.

* build_arg_dict(arg_list) - Converts a list of arguments (as strings in the
    form "name=value") into a dictionary suitable for use with plugins.

* run_datset(action, dataset_name, confdict) - Performs actions related to 
    dataset retrieval and management. 

* run_pipeline(action, pipe_name, args, confdict) - Performs actions related
    to pipeline execution and dependency resolution.

* run_test(pipe_name, test_filename, confdict) - Tests pipelines.

* run_benchmark(pipe_name, args, confdict) - Does what it says on the tin.

* run_plugin(runstr, plugin_name, plugin_dir, plugin_args, confdict) - 
    General execution command for plugins. Currently supports training, testing,
    and normal execution.

* main(argv) - What it says on the tin of most programming languages.

9 - The pipeline module

The pipeline module is comprised of one class definition that abstracts all 
functionality related to running pipelines. 

10 - The plugingen module

This module exists to provide ariadne with the ability to automatically generate
luigi modules given each plugin and its dependencies. 

10.1 - Function list

* genheader(f) - Writes a general plugin header to the given file handle.

* gen_deps_inline(deplist, f, plugindir) - Writes inline dependencies
    (dependencies that are executed serially in the run() method of a luigi
    pipeline) to the given file handle.

* write_dep_def(f, plugin, depnum, argdict, plugindir) - Writes a luigi
    class for each dependency listed. This is only called when a plugin has
    static file outputs (though this can be changed with a custom complete()
    method).

* parse_deps(pl, f, plugindir, args, depnum) - Recursively determines how each
    dependency is to be run and writes all non-inline dependencies to the 
    given file.

* gen(pl, f, wrappername, plugindir, exectype, existingargs, [customoutputline,
        customruncmd])
    - Generates a luigi wrapper for a given plugin. If customoutputline or 
    customcmd are set, gen can be used to generate testing, training, and
    other luigi modules.

*  gentest(pl, f, wrappername, plugindir, exectype, existingargs) - Generates
    a luigi wrapper that tests a given plugin. Support for this function is
    currently experimental, though it demonstrates use cases that may allow
    all dependencies to be scheduled by luigi in the future (it generates
    a custom complete() method, which luigi uses to determine if a dependency
    has executed. Without this method, a luigi task must output a set of 
    files, which ariadne currently cannot generate dynamically.)

11 - Future development directions

As of the time of this writing, ariadne is mostly feature complete. In the 
future, however, a number of changes should be implemented to ensure that
ariadne can be as useful as possible to machine learning researchers.

General tasks:
* A consolidation and overhaul of the plugin system. - There is 
    currently quite a bit of unused code and cruft in the plugin system. 
    This includes features like the generic plugin (plugin.Plugin), explicit
    plugin types in plugin list files, and the fact that plugin list files
    even exist. More error correction and checking would be useful.

* Enabling ariadne to run on remote servers. - To implement this, developers
    will have to either drop support for environment variables in pipelines
    or implement an extremely simple RPC setup in which ariadne can act as a
    remote parent process to luigi instances.

* Changing ariadne's definition file formats to something standard 
    (like XML, etc). Not necessary but may be a "nice to have."

* Reorganizing modules in a coherent way.

* PEP8 compliance (particularly with operators and line widths).

Important new features:
* Support for continuous pipeline execution. This may require a significant
    redesign of how ariadne plugins handle file processing and IO. 
    Alternatively, ariadne could be scheduled either through cron jobs or
    specific triggering events. 

* Support for automatic IO scanning. Because luigi modules are currently
    statically generated, ariadne currently does not automatically schedule
    dependencies for luigi-ification unless they can provide a static list of
    files they modify. This has a number of performance drawbacks.

* Support for file coherence/better dataset integration/networked filesystems.
    Currently, it would be very difficult to coordinate ariadne jobs across 
    different servers if certain resources are only available on a limited
    number of them.
